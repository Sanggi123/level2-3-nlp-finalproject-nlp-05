{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "f4vrUGkBp7DZ"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rJWI3XmoqQW9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AKI_hmnnqjPo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"gunwoo723/kogpt-trinity-poem-generator\").to(device)\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\",\n",
        "  bos_token='<s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(51201, 1920)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.add_special_tokens({'additional_special_tokens': [\"<yun>\"]})\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = '<s>멈춰버린 시계 속 마지막으로 남은 바램\\n'\n",
        "inputs = tokenizer.encode(sentence, add_special_tokens=True, return_tensors='pt').to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids=inputs,\n",
        "        temperature=0.5, # 생성 다양성 조절\n",
        "        min_length=32, # 생성되는 문장의 최소 길이\n",
        "        max_length=256, # 생성되는 문장의 최대 길이\n",
        "        repetition_penalty=1.2, # 반복을 줄이는 패널티\n",
        "        do_sample=True, # 샘플링 기반 생성 활성화\n",
        "        early_stopping=True, # EOS token을 만나면 조기 종료\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "generated_sequence = output[0].tolist()\n",
        "text = tokenizer.decode(generated_sequence, skip_special_tokens=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = text.replace(\"<yun> \", \"\\n\").replace(\"<s> \", \"\").replace(\"</s>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "멈춰버린 시계 속 마지막으로 남은 바램\n",
            "다시 돌아 올 수 없는 그 먼 곳 까지\n",
            "\n",
            "홀로 타향에서 애타게 그리워 하는 \n",
            "잊혀 진 기억속으로 한 걸음 다가서는 이\n",
            "바람에 실려 오는 향수 묻어난다\n",
            "\n",
            "세월의 더께 묻어 둔 채 흘러간 추억들\n",
            "아쉬운 눈길로 다시금 불러 보는 이름\n",
            "이제 다시 볼 수 없음에 서러워라\n",
            "\n",
            "잊힌 기억마저도 되살려 주는 시간들이\n",
            "갈색 낙엽으로 쌓여만 가는 어느 가을날\n",
            "한없이 깊어져간 가슴속 사연들을\n",
            "낙엽따라 떠나가는 하얀 눈송이처럼 날려보낸다\n"
          ]
        }
      ],
      "source": [
        "print(text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyN+1o7ZT89AaH0RyjJRww3h",
      "include_colab_link": true,
      "name": "3. Generater.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
